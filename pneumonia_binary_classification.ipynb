{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pneumonia binary classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84hZ7KIoTgbM",
        "outputId": "76525b09-4d82-43fd-d12a-a9cbd9b24e89"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VShkJugPTi2S"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeul9Jf2Tnil"
      },
      "source": [
        "# params we will probably want to do some hyperparameter optimization later\n",
        "BASE_MODEL= 'ResNet101' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\n",
        "IMG_SIZE = (224, 224) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
        "BATCH_SIZE = 16 # [1, 8, 16, 24]\n",
        "DENSE_COUNT = 128 # [32, 64, 128, 256]\n",
        "DROPOUT = 0.25 # [0, 0.25, 0.5]\n",
        "LEARN_RATE = 1e-4 # [1e-4, 1e-3, 4e-3]\n",
        "TRAIN_SAMPLES = 8000 # [3000, 6000, 15000]\n",
        "TEST_SAMPLES = 800\n",
        "USE_ATTN = False # [True, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFBwdlGuTnnr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ns2X7NfTnzv"
      },
      "source": [
        "import pandas as pd\n",
        "male_adult_df = pd.read_csv('/content/drive/MyDrive/Pneumonia/separated rsna overview/male_df.csv')\n",
        "female_adult_df = pd.read_csv('/content/drive/MyDrive/Pneumonia/separated rsna overview/female_df.csv')\n",
        "child_df = pd.read_csv('/content/drive/MyDrive/Pneumonia/separated rsna overview/child_df.csv')\n",
        "male_pa_df = pd.read_csv('/content/drive/MyDrive/Pneumonia/male_adult_pa_pneumonea/male_adult_pa.csv')\n",
        "female_pa_df = pd.read_csv('/content/drive/MyDrive/Pneumonia/female_adult_pa_pneumonia/female_pa_adult.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMWyHFZFTn4N"
      },
      "source": [
        "#new column, male  = 0, female  = 1\n",
        "male_pa_df['gender'] = 0\n",
        "female_pa_df['gender'] = 1\n",
        "mf_df = pd.concat([male_pa_df,female_pa_df], ignore_index = True)\n",
        "mf_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB4xWGXVZ3nc"
      },
      "source": [
        "mf_df.iloc[0, 5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_jXgMEUB7Y"
      },
      "source": [
        "mf_df.groupby('gender').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FFHmfjqUB86"
      },
      "source": [
        "working_df = mf_df.copy() #male_pa_df.copy() # female_pa_df.copy() #mf_df.copy() # #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhirzLb6UIeL"
      },
      "source": [
        "working_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ludOO_1N8m3N"
      },
      "source": [
        "working_df = working_df.drop(working_df[working_df['class'] == 'No Lung Opacity / Not Normal'].index)\n",
        "working_df['new_class'] = working_df['class'].map({ 'Normal':'Non-Pneumonia','Lung Opacity': 'Pneumonia' })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhioZeGeUIf8"
      },
      "source": [
        "working_df = working_df.drop('Unnamed: 0', axis = 1)\n",
        "#working_df['new_class'] = working_df['class'].map({'No Lung Opacity / Not Normal' : 'Non-Pneumonia', 'Normal':'Non-Pneumonia','Lung Opacity': 'Pneumonia' })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p3KOlZ1bWov"
      },
      "source": [
        "working_df['path'] = working_df['path'].str.replace('../input/rsna-pneumonia-detection-challenge','/content/drive/MyDrive/Pneumonia/rsna dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmL1BjDObtrZ"
      },
      "source": [
        "working_df.iloc[0,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR6_Z2iXqhB4"
      },
      "source": [
        "working_df.groupby('class').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW2bYmCQUIj3"
      },
      "source": [
        "# get the labels in the right format\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "class_enc = LabelEncoder()\n",
        "working_df['class_idx'] = class_enc.fit_transform(working_df['new_class'])\n",
        "oh_enc = OneHotEncoder(sparse=False)\n",
        "working_df['class_vec'] = oh_enc.fit_transform(\n",
        "    working_df['class_idx'].values.reshape(-1, 1)).tolist() \n",
        "working_df.sample(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpXDC_eTUCBK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "image_df = working_df.groupby('patientId').apply(lambda x: x.sample(1))\n",
        "raw_train_df, valid_df = train_test_split(image_df, test_size=0.20, random_state=2018,\n",
        "                                    stratify=image_df['new_class'])\n",
        "print(raw_train_df.shape, 'training data')\n",
        "print(valid_df.shape, 'validation data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiV1lp77UUoF"
      },
      "source": [
        "raw_train_df.groupby('class').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMjgRjtaUUpv"
      },
      "source": [
        "raw_train_df.groupby('new_class').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6RyfFtSUVIB"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
        "raw_train_df.groupby('new_class').size().plot.bar(ax=ax1)\n",
        "#train_df = raw_train_df.groupby('new_class').\\\n",
        "#   apply(lambda x: x.sample(12000//3)).\\\n",
        "#   reset_index(drop=True)\n",
        "train_df = raw_train_df.groupby('class').apply(lambda x: x.sample(n={'Lung Opacity':1076, 'Normal':1076}.get(x.name))).reset_index(drop = True)\n",
        "\n",
        "train_df.groupby('new_class').size().plot.bar(ax=ax2) \n",
        "#train_df.groupby('class').size().plot.bar() \n",
        "print(train_df.shape[0], 'new training size')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugylrxF8YJkB"
      },
      "source": [
        "pip install pydicom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaA6281JUVJq"
      },
      "source": [
        "try:\n",
        "    # keras 2.2\n",
        "    import keras_preprocessing.image.utils as KPImageUtils\n",
        "    import keras_preprocessing.image as KPImage\n",
        "except:\n",
        "    # keras 2.1\n",
        "    import keras.preprocessing.image as KPImage\n",
        "    \n",
        "from PIL import Image\n",
        "import pydicom\n",
        "def read_dicom_image(in_path):\n",
        "    img_arr = pydicom.read_file(in_path).pixel_array\n",
        "    return img_arr/img_arr.max()\n",
        "    \n",
        "class medical_pil():\n",
        "    @staticmethod\n",
        "    def open(in_path):\n",
        "        if '.dcm' in in_path:\n",
        "            c_slice = read_dicom_image(in_path)\n",
        "            int_slice =  (255*c_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n",
        "            return Image.fromarray(int_slice)\n",
        "        else:\n",
        "            return Image.open(in_path)\n",
        "    fromarray = Image.fromarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ-bIBnoUeyg"
      },
      "source": [
        "KPImageUtils.pil_image = medical_pil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzppJDZJUe0O"
      },
      "source": [
        "from PIL import Image\n",
        "KPImageUtils._PIL_INTERPOLATION_METHODS = {\n",
        "        'nearest': Image.NEAREST,\n",
        "        'bilinear': Image.BILINEAR,\n",
        "        'bicubic': Image.BICUBIC,\n",
        "    }\n",
        "\n",
        "def load_img(path, grayscale=False, color_mode='rgb', target_size=None,\n",
        "                 interpolation='nearest'):\n",
        "        \"\"\"Loads an image into PIL format.\n",
        "        # Arguments\n",
        "            path: Path to image file.\n",
        "            grayscale: DEPRECATED use `color_mode=\"grayscale\"`.\n",
        "            color_mode: The desired image format. One of \"grayscale\", \"rgb\", \"rgba\".\n",
        "                \"grayscale\" supports 8-bit images and 32-bit signed integer images.\n",
        "                Default: \"rgb\".\n",
        "            target_size: Either `None` (default to original size)\n",
        "                or tuple of ints `(img_height, img_width)`.\n",
        "            interpolation: Interpolation method used to resample the image if the\n",
        "                target size is different from that of the loaded image.\n",
        "                Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n",
        "                If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
        "                supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
        "                \"hamming\" are also supported.\n",
        "                Default: \"nearest\".\n",
        "        # Returns\n",
        "            A PIL Image instance.\n",
        "        # Raises\n",
        "            ImportError: if PIL is not available.\n",
        "            ValueError: if interpolation method is not supported.\n",
        "        \"\"\"\n",
        "        if grayscale is True:\n",
        "            warnings.warn('grayscale is deprecated. Please use '\n",
        "                          'color_mode = \"grayscale\"')\n",
        "            color_mode = 'grayscale'\n",
        "        if KPImageUtils.pil_image is None:\n",
        "            raise ImportError('Could not import PIL.Image. '\n",
        "                              'The use of `load_img` requires PIL.')\n",
        "        with open(path, 'rb') as f:\n",
        "            img = KPImageUtils.pil_image.open(path)\n",
        "            if color_mode == 'grayscale':\n",
        "                # if image is not already an 8-bit, 16-bit or 32-bit grayscale image\n",
        "                # convert it to an 8-bit grayscale image.\n",
        "                if img.mode not in ('L', 'I;16', 'I'):\n",
        "                    img = img.convert('L')\n",
        "            elif color_mode == 'rgba':\n",
        "                if img.mode != 'RGBA':\n",
        "                    img = img.convert('RGBA')\n",
        "            elif color_mode == 'rgb':\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "            else:\n",
        "                raise ValueError('color_mode must be \"grayscale\", \"rgb\", or \"rgba\"')\n",
        "            if target_size is not None:\n",
        "                width_height_tuple = (target_size[1], target_size[0])\n",
        "                if img.size != width_height_tuple:\n",
        "                    if interpolation not in KPImageUtils._PIL_INTERPOLATION_METHODS:\n",
        "                        raise ValueError(\n",
        "                            'Invalid interpolation method {} specified. Supported '\n",
        "                            'methods are {}'.format(\n",
        "                                interpolation,\n",
        "                                \", \".join(KPImageUtils._PIL_INTERPOLATION_METHODS.keys())))\n",
        "                    resample = KPImageUtils._PIL_INTERPOLATION_METHODS[interpolation]\n",
        "                    img = img.resize(width_height_tuple, resample)\n",
        "            return img\n",
        "\n",
        "        \n",
        "KPImageUtils.load_img = load_img        \n",
        "def _get_batches_of_transformed_samples(self, index_array):\n",
        "    \"\"\"Gets a batch of transformed samples.\n",
        "    # Arguments\n",
        "        index_array: Array of sample indices to include in batch.\n",
        "    # Returns\n",
        "        A batch of transformed samples.\n",
        "    \"\"\"\n",
        "    #for i, n_observation in enumerate(index_array):\n",
        "     #   print(str(i) + \"+ \" + str( n_observation))\n",
        "    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n",
        "    # build batch of image data\n",
        "    # self.filepaths is dynamic, is better to call it once outside the loop\n",
        "    filepaths = self.filepaths\n",
        "    for i, j in enumerate(index_array):\n",
        "        img = KPImageUtils.load_img(filepaths[j],\n",
        "                       color_mode=self.color_mode,\n",
        "                       target_size=self.target_size,\n",
        "                       interpolation=self.interpolation)\n",
        "        x = KPImageUtils.img_to_array(img, data_format=self.data_format)\n",
        "        # Pillow images should be closed after `load_img`,\n",
        "        # but not PIL images.\n",
        "        if hasattr(img, 'close'):\n",
        "            img.close()\n",
        "        if self.image_data_generator:\n",
        "            params = self.image_data_generator.get_random_transform(x.shape)\n",
        "            x = self.image_data_generator.apply_transform(x, params)\n",
        "            x = self.image_data_generator.standardize(x)\n",
        "        batch_x[i] = x\n",
        "    # optionally save augmented images to disk for debugging purposes\n",
        "    if self.save_to_dir:\n",
        "        for i, j in enumerate(index_array):\n",
        "            img = KPImageUtils.array_to_img(batch_x[i], self.data_format, scale=True)\n",
        "            fname = '{prefix}_{index}_{hash}.{format}'.format(\n",
        "                prefix=self.save_prefix,\n",
        "                index=j,\n",
        "                hash=np.random.randint(1e7),\n",
        "                format=self.save_format)\n",
        "            img.save(os.path.join(self.save_to_dir, fname))\n",
        "    # build batch of labels\n",
        "    if self.class_mode == 'input':\n",
        "        batch_y = batch_x.copy()\n",
        "    elif self.class_mode in {'binary', 'sparse'}:\n",
        "        #print(str(self.classes.shape))\n",
        "        #print(str(len(batch_x)))\n",
        "        try:\n",
        "            batch_y = np.empty([len(batch_x), self.classes.shape[1]], dtype=self.dtype)\n",
        "        except:\n",
        "            batch_y = np.empty([len(batch_x), 1], dtype=self.dtype)\n",
        "        #print(batch_y)\n",
        "        \n",
        "        #print(str(len(index_array)))\n",
        "        \n",
        "        #print(str(batch_y.shape))\n",
        "        \n",
        "        for i, n_observation in enumerate(index_array):\n",
        "            #print(self.classes[n_observation])\n",
        "            #print(batch_y[i])\n",
        "            batch_y[i] = self.classes[n_observation]\n",
        "    elif self.class_mode == 'categorical':\n",
        "        batch_y = np.zeros((len(batch_x), len(self.class_indices)),\n",
        "                           dtype=self.dtype)\n",
        "        for i, n_observation in enumerate(index_array):\n",
        "            batch_y[i, self.classes[n_observation]] = 1.\n",
        "    elif self.class_mode == 'multi_output':\n",
        "        batch_y = [output[index_array] for output in self.labels]\n",
        "    elif self.class_mode == 'raw':\n",
        "        batch_y = self.labels[index_array]\n",
        "    else:\n",
        "        return batch_x\n",
        "    if self.sample_weight is None:\n",
        "        return batch_x, batch_y\n",
        "    else:\n",
        "        return batch_x, batch_y, self.sample_weight[index_array]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw4KYx9OUe3l"
      },
      "source": [
        "from keras_preprocessing.image.iterator import BatchFromFilesMixin\n",
        "BatchFromFilesMixin._get_batches_of_transformed_samples = _get_batches_of_transformed_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXoaPA-BUe5N"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "if BASE_MODEL=='VGG16':\n",
        "    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='RESNET52':\n",
        "    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='InceptionV3':\n",
        "    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='Xception':\n",
        "    from keras.applications.xception import Xception as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='DenseNet169': \n",
        "    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='DenseNet121':\n",
        "    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='ResNet50':\n",
        "    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='ResNet101':\n",
        "    from keras.applications.resnet import ResNet101 as PTModel, preprocess_input\n",
        "elif BASE_MODEL=='DenseNet201':\n",
        "    from keras.applications import DenseNet201 as PTModel\n",
        "    from keras.applications.densenet import  preprocess_input\n",
        "else:\n",
        "    raise ValueError('Unknown model: {}'.format(BASE_MODEL))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igNgZfWwf0Ft"
      },
      "source": [
        "Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_l5QrC8U7oz"
      },
      "source": [
        "img_gen_args = dict(samplewise_center=False, \n",
        "                              samplewise_std_normalization=False, \n",
        "                              horizontal_flip = False, \n",
        "                              vertical_flip = False, \n",
        "                              height_shift_range = 0.05, \n",
        "                              width_shift_range = 0.02, \n",
        "                              rotation_range = 3, \n",
        "                              shear_range = 0.01,\n",
        "                              fill_mode = 'nearest',\n",
        "                              zoom_range = 0.05,\n",
        "                              preprocessing_function=preprocess_input,) # preprocessing_function=preprocess_input ###from vgg16 inplace of rescale \n",
        "img_gen = ImageDataGenerator(**img_gen_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2jM6n8EU7qa"
      },
      "source": [
        "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n",
        "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
        "    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n",
        "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
        "                                     class_mode = 'binary',\n",
        "                                              seed = seed,\n",
        "                                    **dflow_args)\n",
        "    df_gen.filenames = in_df[path_col].values\n",
        "    df_gen.classes = np.stack(in_df[y_col].values,0)\n",
        "    df_gen.filepaths.extend(df_gen.filenames)\n",
        "    df_gen.samples = in_df.shape[0]\n",
        "    df_gen.n = in_df.shape[0]\n",
        "    df_gen._set_index_array()\n",
        "    df_gen.directory = '' # since we have the full path\n",
        "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
        "    return df_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn_NvP3zU7uj"
      },
      "source": [
        "train_gen = flow_from_dataframe(img_gen, train_df, #raw train df if use unbalance data\n",
        "                             path_col = 'path',\n",
        "                            y_col = 'class_vec', \n",
        "                            target_size = IMG_SIZE,\n",
        "                             color_mode = 'rgb',\n",
        "                            batch_size = BATCH_SIZE)\n",
        "\n",
        "valid_gen = flow_from_dataframe(img_gen, valid_df, \n",
        "                             path_col = 'path',\n",
        "                            y_col = 'class_vec', \n",
        "                            target_size = IMG_SIZE,\n",
        "                             color_mode = 'rgb',\n",
        "                            batch_size = BATCH_SIZE) # we can use much larger batches for evaluation 256\n",
        "# used a fixed dataset for evaluating the algorithm\n",
        "valid_X, valid_Y = next(flow_from_dataframe(img_gen, \n",
        "                               valid_df, \n",
        "                             path_col = 'path',\n",
        "                            y_col = 'class_vec', \n",
        "                            target_size = IMG_SIZE,\n",
        "                             color_mode = 'rgb', #rgb\n",
        "                            batch_size = TEST_SAMPLES)) # one big batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKlLOe11VAKd"
      },
      "source": [
        "t_x, t_y = next(train_gen)\n",
        "print(t_x.shape, t_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F7o1MwC-TFq"
      },
      "source": [
        "train_gen.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxi31O5wf09Z"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZvRRaYff33p"
      },
      "source": [
        "Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ov2WkH5i36i"
      },
      "source": [
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D, LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam,  RMSprop\n",
        "#with strategy.scope():\n",
        "base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n",
        "                          include_top = False, weights = 'imagenet')\n",
        "base_pretrained_model.trainable = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buit1gZlvuGR"
      },
      "source": [
        "base_pretrained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh1ug9NGVAMM"
      },
      "source": [
        "\n",
        "pt_features = Input(base_pretrained_model.layers[-1].output.shape[1:], name = 'feature_input')\n",
        "pt_depth = base_pretrained_model.layers[-1].output.shape[1:]\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "bn_features = BatchNormalization()(pt_features)\n",
        "gap = GlobalAveragePooling2D()(bn_features)\n",
        "\n",
        "gap_dr = Dropout(DROPOUT)(gap)\n",
        "dr_steps = Dropout(DROPOUT)(Dense(DENSE_COUNT, activation = 'elu')(gap_dr))\n",
        "\n",
        "#dr_steps = BatchNormalization()(dr_steps)\n",
        "#dr_steps = LeakyReLU(0.1)(dr_steps)\n",
        "\n",
        "out_layer = Dense(t_y.shape[1], activation = 'softmax')(dr_steps)\n",
        "\n",
        "attn_model = Model(inputs = [pt_features], \n",
        "                   outputs = [out_layer], name = 'trained_model')\n",
        "pneu_model = Sequential(name = 'combined_model')\n",
        "base_pretrained_model.trainable = False\n",
        "pneu_model.add(base_pretrained_model)\n",
        "pneu_model.add(attn_model)\n",
        "pneu_model.compile(optimizer = RMSprop(lr=0.0001, decay=1e-5), loss = 'binary_crossentropy', #Adam(lr = LEARN_RATE)\n",
        "                           metrics = ['binary_accuracy'])\n",
        "pneu_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avhrYGCLVAPv"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "weight_path=\"{}_weights.best.hdf5\".format('lung_opacity')\n",
        "\n",
        "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
        "                             save_best_only=True, mode='min', save_weights_only = True)\n",
        "\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, \n",
        "                                   patience=10, verbose=1, mode='auto', \n",
        "                                   min_delta=0.0001, cooldown=5, min_lr=0.0001)\n",
        "early = EarlyStopping(monitor=\"val_loss\", \n",
        "                      mode=\"min\", \n",
        "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
        "callbacks_list = [checkpoint, early, reduceLROnPlat]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfBFu_0PVARZ"
      },
      "source": [
        "train_gen.batch_size = BATCH_SIZE\n",
        "history = pneu_model.fit_generator(train_gen, \n",
        "                         steps_per_epoch=train_gen.n//BATCH_SIZE,\n",
        "                         validation_data=(valid_X, valid_Y), \n",
        "                         epochs=10, \n",
        "                         callbacks=callbacks_list,\n",
        "                         workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtDjH6PGVAVA"
      },
      "source": [
        "\n",
        "\n",
        "pred_Y = pneu_model.predict(valid_X, \n",
        "                          batch_size = BATCH_SIZE,  \n",
        "                          verbose = True) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JRQ77meVQkO"
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42J7pYGJVQlw"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "plt.matshow(confusion_matrix(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1)))\n",
        "print(classification_report(np.argmax(valid_Y, -1), \n",
        "                            np.argmax(pred_Y,-1), target_names = class_enc.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJTVj76OVQpA"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "fpr, tpr, _ = roc_curve(np.argmax(valid_Y,-1)==0, pred_Y[:,0])\n",
        "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
        "ax1.plot(fpr, tpr, 'b.-', label = 'Densenet121 (AUC:%2.2f)' % roc_auc_score(np.argmax(valid_Y,-1)==0, pred_Y[:,0]))\n",
        "ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
        "ax1.legend(loc = 4)\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate');\n",
        "ax1.set_title('Lung Opacity ROC Curve')\n",
        "fig.savefig('roc_valid.pdf') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtAhDNDVgAPW"
      },
      "source": [
        "Load local test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh5lk4WiVQqz"
      },
      "source": [
        "local_output = pd.read_csv('/content/drive/MyDrive/Pneumonia/loca_data_output_final/local_data_output_final.csv')\n",
        "local_output = local_output.drop(['Unnamed: 0'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygm7VTZjVee9"
      },
      "source": [
        "local_output['Doctor 1/Ground Truth'] = local_output['Doctor 1/Ground Truth'].map({'No':0, 'Yes': 1})\n",
        "local_output['Doctor 2'] = local_output['Doctor 2'].map({'No':0, 'Yes': 1})\n",
        "local_output['Doctor 3'] = local_output['Doctor 3'].map({'No':0, 'Yes': 1})\n",
        "local_output['class'] = local_output['class'].map({'No':0, 'Yes': 1})\n",
        "local_output.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWP2ZhS1Vego"
      },
      "source": [
        "\n",
        "\n",
        "TEST_DIR2 =  \"/content/drive/MyDrive/Pneumonia/local separated images\"\n",
        "batch_size_test = 1\n",
        "nb_test_samples2 = 129\n",
        "\n",
        "test_generator2 = img_gen.flow_from_directory(\n",
        "    TEST_DIR2,\n",
        "    classes=['male-female-mod'],\n",
        "    # don't generate labels\n",
        "    class_mode='binary',\n",
        "    # don't shuffle\n",
        "    shuffle=False,\n",
        "    target_size = IMG_SIZE,\n",
        "    color_mode = 'rgb',\n",
        "    batch_size=batch_size_test,)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi9anucNVekt"
      },
      "source": [
        "test_generator2.reset()\n",
        "preds2 = pneu_model.predict_generator(test_generator2, workers = 1,steps=np.ceil(nb_test_samples2/batch_size_test)) #changed worker to 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0tmMhIIVlrQ"
      },
      "source": [
        "\n",
        "\n",
        "preds2 = np.argmax(preds2, axis=-1)\n",
        "data = {'col_1': test_generator2.filenames, 'col_2': preds2}\n",
        "df=pd.DataFrame.from_dict(data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG08cHUdVls3"
      },
      "source": [
        "import re\n",
        "\n",
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "\n",
        "def natural_keys(text):\n",
        "    '''\n",
        "    alist.sort(key=natural_keys) sorts in human order\n",
        "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
        "    (See Toothy's implementation in the comments)\n",
        "    '''\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El07WEOzVlww"
      },
      "source": [
        "ids = [x for x in df['col_1'] ]\n",
        "ids = [natural_keys(x)[1] for x in ids]\n",
        "df['ID'] = np.asarray(ids)\n",
        "df = df.sort_values(by='ID')\n",
        "df = df.reset_index(drop  =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsXyHHZEVtWD"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkY8jUjxVwEr"
      },
      "source": [
        "df[df['col_2'] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdCLh9ZZOgni"
      },
      "source": [
        "df[df['col_2'] == 1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkYNr-7nVwGZ"
      },
      "source": [
        "plt.matshow(confusion_matrix(np.asarray(local_output['class']), np.asarray(df['col_2'])))\n",
        "print(classification_report(np.asarray(local_output['class']), \n",
        "                           np.asarray(df['col_2']), target_names = class_enc.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_VrM382VwLP"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "fpr, tpr, _ = roc_curve(np.asarray(local_output['class'])==0, np.asarray(df['col_2'] == 0))\n",
        "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
        "ax1.plot(fpr, tpr, 'b.-', label = 'Densenet121 (AUC:%2.2f)' % roc_auc_score(np.asarray(local_output['class'])==0,np.asarray(df['col_2'] == 0)))\n",
        "ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
        "ax1.legend(loc = 4)\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate');\n",
        "ax1.set_title('Lung Opacity ROC Curve')\n",
        "fig.savefig('roc_valid.pdf') \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUB93xg2VwM5"
      },
      "source": [
        "pneu_model.save('resnet101.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ilzMtwkjDYO"
      },
      "source": [
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "from skimage import transform\r\n",
        "def load(filename):\r\n",
        "   np_image = Image.open(filename)\r\n",
        "   np_image = np.array(np_image).astype('float32')/255\r\n",
        "   np_image = transform.resize(np_image, (224, 224, 3))\r\n",
        "   np_image = np.expand_dims(np_image, axis=0)\r\n",
        "   return np_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uznYlN6t6KKW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3-91Y0XexOj"
      },
      "source": [
        "Prediction for each image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwIqfnK-5Jvs"
      },
      "source": [
        "ids = [i for i in df['ID']]\r\n",
        "preds = []\r\n",
        "for i in ids:\r\n",
        "  image = load('/content/drive/MyDrive/Pneumonia/local separated images/male-female-mod/' + str(i) + '.jpg')\r\n",
        "  pred = pneu_model.predict(image)\r\n",
        "  preds.append(pred)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AcYKIxo5ocH"
      },
      "source": [
        "data = {'image_id':ids , 'probability(no and yes)': preds}\r\n",
        "df=pd.DataFrame.from_dict(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9oYzVbE78Tz"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FguXTHJ3788B"
      },
      "source": [
        "df.to_csv('male female pa resnet101.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQlUb7jV8v_N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}